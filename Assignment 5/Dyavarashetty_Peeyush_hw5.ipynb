{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"V0XIJBPlGp7G"},"outputs":[],"source":["%matplotlib inline"]},{"cell_type":"markdown","metadata":{"id":"F3MJ5p6XtAfP"},"source":["Save the python notebook as lastname_firstname_hw5.ipynb\n","\n","- Name: Dyavarashetty Peeyush\n","- UID: 120428104"]},{"cell_type":"markdown","metadata":{"id":"7HHaYItqGp7K"},"source":["\n","Training a Classifier (50 points)\n","=====================\n","\n","You'll be using the cifar10 which is a benchmark dataset widely used for image classification tasks in machine learning and computer vision. It consists of 60,000 32x32 color images in 10 classes, with 6,000 images per class, making it ideal for training and evaluating algorithms.\n","\n","Please write the code wherever \"\"\" write the code here\"\"\" is mentioned.\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"aiDTtCmnGp7N"},"outputs":[],"source":["# Importing required methods and functions\n","\n","import torch\n","import torchvision\n","import torchvision.transforms as transforms"]},{"cell_type":"markdown","metadata":{"id":"jrn999yRGp7O"},"source":["The output of torchvision datasets are PILImage images of range [0, 1].\n","We transform them to Tensors of normalized range [-1, 1].\n","\n","- 10 points\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"jjqc4pOeGp7P"},"outputs":[],"source":["import torch.utils\n","import torch.utils.data\n","\n","\n","transform = transforms.Compose(\n","    [transforms.ToTensor(),\n","     transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n","\n","trainset = torchvision.datasets.CIFAR10(root='./data', train=True,\n","                                        download=True, transform=transform)\n","\n","# Use torch.utils.data.DataLoader to create a DataLoader instance for training data\n","# Set batch_size to control the number of samples in each batch\n","# Set shuffle=True to shuffle the training data for each epoch\n","# Set num_workers to specify the number of subprocesses to use for data loading\n","\n","trainloader = torch.utils.data.DataLoader(dataset=trainset, \n","                                          batch_size=20, shuffle=True, \n","                                          num_workers=8) #\"\"\"Write the code here\"\"\"\n","\n","testset = torchvision.datasets.CIFAR10(root='./data', train=False,\n","                                       download=True, transform=transform) \n","\n","# Create a DataLoader instance for test data similar to trainloader\n","# Set shuffle=False since shuffling is not necessary for testing/validation\n","\n","testloader = torch.utils.data.DataLoader(dataset=trainset, \n","                                          batch_size=20, shuffle=False, \n","                                          num_workers=8) #\"\"\"Write the code here\"\"\"\n","\n","classes = ('plane', 'car', 'bird', 'cat',\n","           'deer', 'dog', 'frog', 'horse', 'ship', 'truck')"]},{"cell_type":"markdown","metadata":{"id":"M6vamfZlGp7Q"},"source":["Displaying some training images\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"axlP3-SOGp7Q"},"outputs":[],"source":["import matplotlib.pyplot as plt\n","import numpy as np\n","\n","# functions to show an image\n","\n","\n","def imshow(img):\n","    img = img / 2 + 0.5     # unnormalize\n","    npimg = img.numpy()\n","    plt.imshow(np.transpose(npimg, (1, 2, 0)))\n","\n","\n","# get some random training images\n","dataiter = iter(trainloader)\n","images, labels = next(dataiter)\n","\n","# show images\n","imshow(torchvision.utils.make_grid(images))\n","# print labels\n","print(' '.join('%5s' % classes[labels[j]] for j in range(4)))"]},{"cell_type":"markdown","metadata":{"id":"uWOltvLbGp7R"},"source":["2. Define a Convolution Neural Network\n","\n","- 10 points\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"DraFhbzeGp7S"},"outputs":[],"source":["import torch.nn as nn\n","import torch.nn.functional as F\n","\n","\n","class Net(nn.Module):\n","    def __init__(self):\n","        super(Net, self).__init__()\n","        self.conv1 = nn.Conv2d(3, 6, 5)\n","        self.pool = nn.MaxPool2d(2, 2)\n","        self.conv2 = nn.Conv2d(6, 16, 5)\n","        self.fc1 = nn.Linear(16 * 5 * 5, 120)\n","        self.fc2 = nn.Linear(120, 84)\n","        self.fc3 = nn.Linear(84, 10)\n","\n","    def forward(self, x):\n","        \"\"\"Write the code here\"\"\"\n","        # Perform first convolution operation followed by ReLU activation function\n","        x = self.conv1(x)\n","        x = F.relu(x)\n","        # Perform max pooling operation\n","        x = self.pool(x)\n","        # Perform second convolution operation followed by ReLU activation function\n","        x = self.conv2(x)\n","        x = F.relu(x)\n","        # Perform max pooling operation\n","        x = self.pool(x)\n","        # Reshape the tensor for fully connected layers\n","        x = torch.reshape(x, (-1, 16 * 5 * 5))\n","        # Perform first fully connected layer operation followed by ReLU activation function\n","        x = self.fc1(x)\n","        x = F.relu(x)\n","        # Perform second fully connected layer operation followed by ReLU activation function\n","        x = self.fc2(x)\n","        x = F.relu(x)\n","        # Perform the third fully connected layer operation\n","        x = self.fc3(x)\n","        return x\n","\n","\n","net = Net()"]},{"cell_type":"markdown","metadata":{"id":"aU4BI4oYGp7S"},"source":["3. Define a Loss function and optimizer\n","\n","- 10 points\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"rlqUpgyYGp7T"},"outputs":[],"source":["import torch.optim as optim\n","\n","# Define a loss function\n","criterion = nn.CrossEntropyLoss()#\"\"\"Write the code here\"\"\"\n","\n","# Define an optimizer for ex. ADAM, SGD, RMS\n","optimizer = optim.SGD(params=net.parameters(), lr=5 * 1e-3, momentum=0.9) #\"\"\"Write the code here\"\"\"\n"]},{"cell_type":"markdown","metadata":{"id":"_jOyUQw0Gp7T"},"source":["4. Train the network\n","- 10 points\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"HLQSfKXHGp7U"},"outputs":[],"source":["for epoch in range(10):  # loop over the dataset multiple times\n","\n","    running_loss = 0.0\n","    for i, data in enumerate(trainloader, 0):\n","        # get the inputs\n","        inputs, labels = data\n","        # zero the parameter gradients\n","        net.zero_grad() #\"\"\"Write the code here\"\"\"\n","\n","        # forward + backward + optimize\n","        outputs = net.forward(x=inputs) #\"\"\"Write the code here\"\"\"\n","        loss = criterion(outputs, labels.long()) #\"\"\"Write the code here\"\"\"\n","        loss.backward()\n","        optimizer.step()\n","\n","        # print statistics\n","        running_loss += loss.item()\n","        if i % 2000 == 1999:    # print every 2000 mini-batches\n","            print('[%d, %5d] loss: %.3f' %\n","                  (epoch + 1, i + 1, running_loss / 2000))\n","            running_loss = 0.0\n","\n","print('Finished Training')"]},{"cell_type":"markdown","metadata":{"id":"Yj60_dNCGp7U"},"source":["5. Test the network on the test data\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"VTgqApxUGp7U"},"outputs":[],"source":["dataiter = iter(testloader)\n","images, labels = next(dataiter)\n","\n","# print images\n","imshow(torchvision.utils.make_grid(images))\n","print('GroundTruth: ', ' '.join('%5s' % classes[labels[j]] for j in range(4)))"]},{"cell_type":"markdown","metadata":{"id":"j7I5IjEDGp7V"},"source":["Okay, now let us see what the neural network thinks these examples above are:\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"jyr3Wbm0Gp7V"},"outputs":[],"source":["outputs = net(images)"]},{"cell_type":"markdown","metadata":{"id":"WR3hChaUGp7V"},"source":["The outputs are energies for the 10 classes.\n","Higher the energy for a class, the more the network\n","thinks that the image is of the particular class.\n","So, let's get the index of the highest energy:\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"a_0tArk_Gp7W"},"outputs":[],"source":["_, predicted = torch.max(outputs, 1)\n","\n","print('Predicted: ', ' '.join('%5s' % classes[predicted[j]]\n","                              for j in range(4)))"]},{"cell_type":"markdown","metadata":{"id":"P0FX0YwQGp7W"},"source":["The results seem pretty good.\n","\n","Let us look at how the network performs on the whole dataset.\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"dyHBgt0JGp7W"},"outputs":[],"source":["correct = 0\n","total = 0\n","with torch.no_grad():\n","    for data in testloader:\n","        images, labels = data\n","        outputs = net(images)\n","        _, predicted = torch.max(outputs.data, 1)\n","        total += labels.size(0)\n","        correct += (predicted == labels).sum().item()\n","\n","print('Accuracy of the network on the 10000 test images: %d %%' % (\n","    100 * correct / total))"]},{"cell_type":"markdown","metadata":{"id":"pvroOj37Gp7W"},"source":["That looks way better than chance, which is 10% accuracy (randomly picking\n","a class out of 10 classes).\n","Seems like the network learnt something.\n","\n","what are the classes that performed well, and the classes that did\n","not perform well:\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"e0Bkv3nBGp7Y"},"outputs":[],"source":["class_correct = list(0. for i in range(10))\n","class_total = list(0. for i in range(10))\n","with torch.no_grad():\n","    for data in testloader:\n","        images, labels = data\n","        outputs = net(images)\n","        _, predicted = torch.max(outputs, 1)\n","        c = (predicted == labels).squeeze()\n","        for i in range(4):\n","            label = labels[i]\n","            class_correct[label] += c[i].item()\n","            class_total[label] += 1\n","\n","\n","for i in range(10):\n","    print('Accuracy of %5s : %2d %%' % (\n","        classes[i], 100 * class_correct[i] / class_total[i]))"]},{"cell_type":"markdown","metadata":{"id":"pBYc04g7u0hs"},"source":["Reflecting on your experience with training and evaluating a CIFAR-10 classification model, discuss one significant challenge you encountered during the process and how you addressed it. Additionally, explain why classifying images into these specific categories (airplane, automobile, bird, etc.) might be important in real-world applications.\n","\n","- 10 points"]},{"cell_type":"markdown","metadata":{},"source":["Challenges encountered:\n","\n","1) Understanding new datatypes such as tensors.DataLoader and how to extract data from it.\n","\n","2) Setting correct loss function and plugging the loss according to it. I first used `nn.MSELoss()`, which always requires Euclidean distance. So, while training using the neural networks, I always get an error because `labels` and `outputs` have different dimension.\n","\n","3) Setting `batch_size`. If `batch_size` is 15 or 10 or 32, the model does not learn correctly. I learnt that the batch size is important while plugging in the model.\n","\n","4) Improving accuracy while trying SGD and ADAM. Found that SGD is better.\n","\n","Importance of classifying images in real-world applications:\n","\n","1) Sorting various images in web either for showing or for e-commerce. Since, internet has a lot of images, to search for an image is harder when they are not classified. For example, if there is no classification in the internet, finding how animals (even a particular animal such as husky dog, german shepard), monument (Taj Mahal, Effiel Tower, Leaning Tower of Pisa, etc), object or any other pictorial information is hard. \n","\n","2) For wildlife monitoring, classification of different species of animals is important to monitor because they can keep track of count and can understand behaviours easily than searching for them and analyzing.\n","\n","3) For autonomous vehicles, detecting different classified objects such as cars, persons, animals, birds and so on are important, even for aviation safety because if not detected, the chances of accident are high."]}],"metadata":{"colab":{"provenance":[]},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.9"}},"nbformat":4,"nbformat_minor":0}
